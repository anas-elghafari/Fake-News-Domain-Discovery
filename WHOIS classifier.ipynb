{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Notebook demonstraing a classifier of domains into 'msm' or 'fake' based on WHOIS info.\n",
    "\n",
    "requires the following external modules: scikit-learn, numpy, pythonwhois\n",
    "\n",
    "Also requires the pickle file (available in this repository): \"enriched_whois_features.p\"\n",
    "\n",
    "For more details about constructing feature vectors and evaluating the classifier, see the other notebook: \n",
    "\"Evaluating Domain Classification with Whois\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pythonwhois\n",
    "from collections import defaultdict\n",
    "from dateutil.parser import parse\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "import pickle, datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function for getting fully-prefixed string attributes from the json data returned by the pythonwhois library\n",
    "def get_kv_strings(kprefix, d):\n",
    "    result = []\n",
    "    if hasattr(d, \"keys\"):\n",
    "        for k, v in d.items():\n",
    "            if k ==\"raw\":\n",
    "                continue\n",
    "            else:\n",
    "                result.extend(get_kv_strings(kprefix+ \"/\" +k, v))\n",
    "    elif isinstance(d, list):\n",
    "        for e in d:\n",
    "            result.append(kprefix + \" : \" + str(e))\n",
    "    else:\n",
    "        result.append(kprefix + \" : \" + str(d))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Enriching the features vector by adding info about whether the domain is older than 2,5,10 years. Also add information\n",
    "#about the day of week and hour of dat when the domain was created/updated.\n",
    "\n",
    "days_nums_strings = {0:\"Monday\", 1:\"Tuesday\", 2:\"Wednesday\", 3:\"Thursday\",4:\"Friday\", 5:\"Saturday\", 6:\"Sunday\"}\n",
    "\n",
    "def enrich_vector(fv):\n",
    "    newv = [\"/domain_name: \" + fv[0][0].lower().strip()]  #adding the domain name as an additional feature, because it is not there\n",
    "    dateval = \"\"\n",
    "    for val in fv[1:]:\n",
    "        val = val.lower()\n",
    "        if val.startswith(\"/creation_date\"):\n",
    "            dateval = parse(val[val.index(\": \")+2:])\n",
    "            year = int(dateval.year)\n",
    "            newv.append(\"/creation_year: \" + str(year))\n",
    "            newv.append(\"/domain older than 2 years: \" + str(year<2016))\n",
    "            newv.append(\"/domain older than 5 years: \" + str(year<2013))\n",
    "            newv.append(\"/domain older than 10 years: \" + str(year<2008))\n",
    "            weekday = dateval.weekday()\n",
    "            newv.append(\"/creation weekday: \" + days_nums_strings[weekday])\n",
    "            newv.append(\"/created on weekend: \" + str(weekday in [5,6]))\n",
    "            hour = dateval.hour\n",
    "            newv.append(\"/created outside typical business hours: \" + str((hour>18 or hour <8)))\n",
    "            #print(\"creation date: \", dateval)\n",
    "            \n",
    "        if val.startswith(\"/updated_date\"):\n",
    "            dateval = parse(val[val.index(\": \")+2:])\n",
    "            weekday = dateval.weekday()\n",
    "            newv.append(\"/update weekday: \" + days_nums_strings[weekday])\n",
    "            newv.append(\"/updated on weekend: \" + str(weekday in [5,6]))\n",
    "            hour = dateval.hour\n",
    "            newv.append(\"/updated outside typical business hours: \" + str((hour>18 or hour <8)))\n",
    "            #print(\"update date: \", dateval)\n",
    "            \n",
    "        if val.startswith(\"/nameservers\"):\n",
    "            nameserver = val[val.index(\": \")+2:]\n",
    "            nameserver_domain = nameserver.split(\".\")\n",
    "            nameserver_domain = \".\".join(nameserver_domain[-2:])\n",
    "            newv.append(\"/nameserver_domain: \"+ nameserver_domain.upper())\n",
    "            \n",
    "        if val.find(\"@\")>-1:\n",
    "            #look at the email domain\n",
    "            email_domain = val[val.index(\"@\")+1:]\n",
    "            newv.append(\"/email_domain: \"+ email_domain)\n",
    "            \n",
    "    newv = sorted(set(newv))  #get rid of duplicates, especially from nameserver normalization\n",
    "    #print(\"newv:\\n\", \"\\n\".join(newv))\n",
    "    ret = [x for x in fv]\n",
    "    ret.extend(newv)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_dimensions(instances):\n",
    "    features = defaultdict(lambda: 0)\n",
    "    for current_instance in instances:\n",
    "        #print(\"curret instance: \", current_instance[0:2])\n",
    "        for d in set(current_instance[1:]):\n",
    "            features[d] +=1\n",
    "            \n",
    "    print(\"\\n\\nNumber of instances: \", len(instances))\n",
    "    print(\"Total number of possible features: \", len(features))\n",
    "    selected_features = sorted(features.keys())\n",
    "    return selected_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insts_to_binary_vecs(insts, dimensions):\n",
    "    vecs = np.zeros(shape = [len(insts), len(dimensions)], dtype='uint')\n",
    "    for i, inst in enumerate(insts):\n",
    "        #print(\"building vector for instance:\", inst[0])\n",
    "        vec = np.array([0 if not d in inst[1:] else 1 for d in dimensions])\n",
    "        vecs[i] = (vec)\n",
    "    return vecs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_enriched_vec_for_domain(dimensions, domain_name, label):\n",
    "    w =  pythonwhois.get_whois(domain_name)\n",
    "    w_iana = pythonwhois.get_whois(domain_name.strip(), server='whois.iana.org')\n",
    "    vec = []\n",
    "    vec.extend(get_kv_strings(\"\", w))\n",
    "    vec.extend(get_kv_strings(\"\", w_iana))\n",
    "    vec = sorted(set(vec))\n",
    "    vec.insert(0, (domain_name, label))\n",
    "    enriched_v = enrich_vector(vec)\n",
    "    bvec = insts_to_binary_vecs([enriched_v], dimensions)\n",
    "    return bvec\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#get a trained classifier starting from a list of enriched vectors:\n",
    "def get_trained_model(instances):\n",
    "    dimensions = select_dimensions(instances)\n",
    "    binary_vecs = insts_to_binary_vecs(instances, dimensions)\n",
    "    domain_names = [x[0] for x in instances]\n",
    "    instance_vectors = []\n",
    "    for domain_name, bvec in zip(domain_names, binary_vecs):\n",
    "        inst = [domain_name]\n",
    "        inst.extend(bvec)\n",
    "        instance_vectors.append(inst)\n",
    "        \n",
    "    y_train = [inst[0][1] for inst in instance_vectors]\n",
    "    x_train = [inst[1:] for inst in instance_vectors]\n",
    "    m = linear_model.LogisticRegression(C=1e5)\n",
    "    t1 = datetime.datetime.now()\n",
    "    m.fit(x_train, y_train)\n",
    "    t2 = datetime.datetime.now()\n",
    "    print(\"Training the model finished in:\", t2-t1)\n",
    "    return m, dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#take a list of new labeled domains and add that to the training\n",
    "def update_training(dimensions, existing_instances, list_labeled_domains):\n",
    "    new_instances = []\n",
    "    for i in list_labeled_domains:\n",
    "        if not len(i) == 2 or not i[1] in {\"fake\", \"msm\"}:\n",
    "            print(\"Error: each instance must be a pair of a domain name followed by the label 'fake' or 'msm'.\")\n",
    "        new_instances.append(create_enriched_vec_for_domain(dimensions, i[0], i[1]))\n",
    "    existing_instances.extend(new_instances)\n",
    "    updated_classifier = get_trained_model(existing_instances)[0]\n",
    "    return updated_classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prediction(model, dimensions, domain_name):\n",
    "    bvec = create_enriched_vec_for_domain(dimensions, domain_name, \"\")\n",
    "    pred = model.predict(bvec)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loaded. Number of training instances:  700\n"
     ]
    }
   ],
   "source": [
    "#loading the training instances from the pickle file:\n",
    "instances = pickle.load(open(\"enriched_whois_features.p\", \"rb\"))\n",
    "print(\"Training loaded. Number of training instances: \", len(instances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cnn.com', 'msm'),\n",
       " '/contacts/admin : None',\n",
       " '/contacts/billing : None',\n",
       " '/contacts/registrant : None',\n",
       " '/contacts/tech : None',\n",
       " '/creation_date : 1993-09-22 04:00:00',\n",
       " '/emails : domainabuse@cscglobal.com',\n",
       " '/expiration_date : 2018-09-21 04:00:00',\n",
       " '/id : 3269879_DOMAIN_COM-VRSN',\n",
       " '/nameservers : NS-1086.AWSDNS-07.ORG',\n",
       " '/nameservers : NS-1630.AWSDNS-11.CO.UK',\n",
       " '/nameservers : NS-47.AWSDNS-05.COM',\n",
       " '/nameservers : NS-576.AWSDNS-08.NET',\n",
       " '/registrar : CSC Corporate Domains, Inc.',\n",
       " '/status : clientTransferProhibited https://icann.org/epp#clientTransferProhibited',\n",
       " '/status : serverDeleteProhibited https://icann.org/epp#serverDeleteProhibited',\n",
       " '/status : serverTransferProhibited https://icann.org/epp#serverTransferProhibited',\n",
       " '/status : serverUpdateProhibited https://icann.org/epp#serverUpdateProhibited',\n",
       " '/updated_date : 2017-02-15 17:31:58',\n",
       " '/whois_server : whois.corporatedomains.com',\n",
       " '/created on weekend: False',\n",
       " '/created outside typical business hours: True',\n",
       " '/creation weekday: Wednesday',\n",
       " '/creation_year: 1993',\n",
       " '/domain older than 10 years: True',\n",
       " '/domain older than 2 years: True',\n",
       " '/domain older than 5 years: True',\n",
       " '/email_domain: cscglobal.com',\n",
       " '/nameserver_domain: AWSDNS-05.COM',\n",
       " '/nameserver_domain: AWSDNS-07.ORG',\n",
       " '/nameserver_domain: AWSDNS-08.NET',\n",
       " '/nameserver_domain: CO.UK',\n",
       " '/update weekday: Wednesday',\n",
       " '/updated on weekend: False',\n",
       " '/updated outside typical business hours: False']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examining some training instances.\n",
    "instances[305]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Number of instances:  700\n",
      "Total number of possible features:  5494\n",
      "Training the model finished in: 0:00:00.658149\n"
     ]
    }
   ],
   "source": [
    "#trainging the classifier:\n",
    "classifier, dimensions = get_trained_model(instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['msm']\n"
     ]
    }
   ],
   "source": [
    "#example of how to get some prediction from the classifier\n",
    "print(get_prediction(classifier, dimensions, \"usatoday.com\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fake']\n"
     ]
    }
   ],
   "source": [
    "print(get_prediction(classifier, dimensions, \"worldtruth.tv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Number of instances:  702\n",
      "Total number of possible features:  5494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model finished in: 0:00:00.637599\n"
     ]
    }
   ],
   "source": [
    "#Example for how to add new training instances:\n",
    "\n",
    "new_instances  = [(\"ladiesofliberty.net\", \"fake\"), (\"theatlantic.com\", \"msm\")]\n",
    "classifier = update_training(dimensions, instances, new_instances)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
